{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd098b1",
   "metadata": {},
   "source": [
    "## Code for report \n",
    "#### Author: Liu Peijun\n",
    "#### Date 2022/11/25\n",
    "### Content\n",
    "### 1. Download XBRL Files from EDINET API\n",
    "    1.1 Extract File Index from EDINET Search\n",
    "    1.2 Download Annual Report as XBRL files\n",
    "    1.3 Execute and View Outputs\n",
    "### 2. Extract Text Data from XBRL Files\n",
    "    2.1 Set up Text Intepreter: MeCab (with basic dictionary)\n",
    "    2.2 Extract Text data from BusinessRisksText\n",
    "    2.3 Cleanning Text data\n",
    "    2.4 Execute and View Outputs\n",
    "### 3. Calculate Stickiness Score and Export to Stata\n",
    "    3.1 Merge year-level Data into one Dataset\n",
    "    3.2 Define and Calculate Stickiness Measures\n",
    "    3.3  Export to Stata\n",
    "### 4. Process and Report via Stata  \n",
    "    4.1 Import Stata \n",
    "    4.2 Processing and Display Textual-Related Data\n",
    "    4.3 Merge with Financial Data and Conduct Simple Statistical Test\n",
    "\n",
    "\n",
    "Note: Codes displayed in this page is not necessarily able to run on Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2edffc",
   "metadata": {},
   "source": [
    "### 1. Download XBRL Files from EDINET API\n",
    "#### 1.1 Extract File Index from EDINET Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131139ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load Requested Libraries\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd523ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_day_list(start_date, end_date):\n",
    "    print(\"start_date：\", start_date)\n",
    "    print(\"end_day：\", end_date)\n",
    "\n",
    "    period = end_date - start_date                   # calculate the length of period\n",
    "    period = int(period.days)\n",
    "    day_list = []\n",
    "\n",
    "    for d in range(period):\n",
    "        day = start_date + datetime.timedelta(days=d)\n",
    "        day_list.append(day)\n",
    "\n",
    "    day_list.append(end_date)\n",
    "\n",
    "    return day_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5474ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_download_dir(start_date,end_date):\n",
    "    start_year = start_date.year \n",
    "    end_year = end_date.year\n",
    "    \n",
    "    year_identifier = str(start_year) + '_' + str(end_year)\n",
    "    path = 'D:/Study/Data/XBRL/' + year_identifier\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except FileExistsError:\n",
    "        print(f'This file {path} has already exist')\n",
    "    \n",
    "    return year_identifier,path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b36272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_doc_id_list(day_list,year_identifier,download_dir):\n",
    "    doc_list_message = []\n",
    "    \n",
    "    securities_seccode_list = []\n",
    "    firm_name_list = []\n",
    "    securities_report_doc_list = []\n",
    "    period_starttime_list = []\n",
    "    period_endtime_list = []\n",
    "    doc_typecode_list = []\n",
    "    doc_description_list = []\n",
    "\n",
    "    for index, day in enumerate(day_list):\n",
    "        time.sleep(1)\n",
    "        url = \"https://disclosure.edinet-fsa.go.jp/api/v1/documents.json\"\n",
    "        params = {\"date\": day, \"type\": 2}\n",
    "        proxies = {\n",
    "            \"http_proxy\": \"http://username:password@proxy.example.com:8080\",\n",
    "            \"https_proxy\": \"https://username:password@proxy.example.com:8080\"\n",
    "        }\n",
    "        res = requests.get(url, params=params, proxies=proxies)\n",
    "        json_data = res.json()\n",
    "        doc_list_message.append(day.strftime('%m/%d/%Y'))\n",
    "        \n",
    "        for num in range(len(json_data[\"results\"])):\n",
    "            ordinance_code = json_data[\"results\"][num][\"ordinanceCode\"]\n",
    "            form_code = json_data[\"results\"][num][\"formCode\"]\n",
    "            sec_code = json_data[\"results\"][num][\"secCode\"]\n",
    "            \n",
    "            if ordinance_code == \"010\" and form_code == \"030000\" and sec_code is not None:\n",
    "                message = str(json_data[\"results\"][num][\"filerName\"]) + ' '+ str(json_data[\"results\"][num][\"docDescription\"]) + ' '+str(json_data[\"results\"][num][\"docID\"]) + ' '+ str(json_data[\"results\"][num][\"secCode\"])\n",
    "                doc_list_message.append(message)\n",
    "                \n",
    "                securities_seccode_list.append(json_data[\"results\"][num][\"secCode\"])\n",
    "                firm_name_list.append(json_data[\"results\"][num][\"filerName\"])\n",
    "                securities_report_doc_list.append(json_data[\"results\"][num][\"docID\"])\n",
    "                doc_description_list.append(json_data[\"results\"][num][\"docDescription\"])\n",
    "                doc_typecode_list.append(json_data[\"results\"][num][\"docTypeCode\"])\n",
    "                period_starttime_list.append(json_data[\"results\"][num][\"periodStart\"])\n",
    "                period_endtime_list.append(json_data[\"results\"][num][\"periodEnd\"])\n",
    "                \n",
    "    txt_name = download_dir + '/' + year_identifier + ' download_process.txt'\n",
    "    with open(txt_name,'a') as f:\n",
    "        for line in doc_list_message:\n",
    "            f.write(f\"{line}\\n\")\n",
    "        \n",
    "    securities_df = pd.DataFrame()\n",
    "    securities_df[\"stkno\"] = securities_seccode_list\n",
    "    securities_df[\"ID\"] = firm_name_list\n",
    "    securities_df[\"Type\"] = doc_description_list\n",
    "    securities_df[\"typecode\"] = doc_typecode_list\n",
    "    securities_df[\"Doc ID\"] = securities_report_doc_list\n",
    "    securities_df[\"start\"] = period_starttime_list\n",
    "    securities_df[\"end\"] = period_endtime_list\n",
    "    \n",
    "    csv_path = download_dir + '/' + year_identifier + '.csv'\n",
    "    securities_df.to_csv(csv_path)                              \n",
    " \n",
    "    return securities_report_doc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801cb00a",
   "metadata": {},
   "source": [
    "#### 1.2 Download Annual Report as XBRL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f47dddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_xbrl_in_zip(securities_report_doc_list, number_of_lists,year_identifier,download_dir):\n",
    "    download_df = pd.DataFrame()\n",
    "    download_id = []\n",
    "    download_message = []\n",
    "    \n",
    "    for index, doc_id in enumerate(securities_report_doc_list):\n",
    "        time.sleep(2)\n",
    "        url = \"https://disclosure.edinet-fsa.go.jp/api/v1/documents/\" + doc_id\n",
    "        params = {\"type\": 1}\n",
    "        filename = download_dir + '/'+ doc_id  + \".zip\"   \n",
    "        res = requests.get(url, params=params, stream=True)\n",
    "        \n",
    "        if res.status_code == 200:\n",
    "            download_id.append(doc_id)\n",
    "            message = doc_id, \":\", index + 1, \"/\", number_of_lists\n",
    "            download_message.append(message)\n",
    "            \n",
    "            with open(filename, 'wb') as file:\n",
    "                for chunk in res.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)\n",
    "        \n",
    "    download_path = download_dir + '/' + year_identifier + ' download_check.csv'\n",
    "\n",
    "    download_df[\"download_ID\"] = download_id\n",
    "    download_df[\"download_check\"] = download_message\n",
    "    download_df.to_csv(download_path)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a486e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start_date,end_date):\n",
    "    \n",
    "    # Make list of acquired files\n",
    "    day_list = make_day_list(start_date, end_date)\n",
    "    # Creating File Directories\n",
    "    year_identifier, download_dir = set_download_dir(start_date,end_date)\n",
    "    \n",
    "    securities_report_doc_list = make_doc_id_list(day_list,year_identifier,download_dir)\n",
    "    number_of_lists = len(securities_report_doc_list)\n",
    "    print(\"number of lists acquired：\", len(securities_report_doc_list))\n",
    "\n",
    "    # Start downloading XBRL files\n",
    "    print(\"get_list：\", securities_report_doc_list[:10], \"and etc.\")\n",
    "    print(\"download starts\")\n",
    "    download_xbrl_in_zip(securities_report_doc_list, number_of_lists,year_identifier,download_dir)\n",
    "    print(\"download finished\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a70482",
   "metadata": {},
   "source": [
    "#### 1.3 Execute and View Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3d3805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 392 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stkno</th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>typecode</th>\n",
       "      <th>Doc ID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78700</td>\n",
       "      <td>福島印刷株式会社</td>\n",
       "      <td>有価証券報告書－第65期(平成28年8月21日－平成29年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BSAW</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>2017-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76070</td>\n",
       "      <td>株式会社進和</td>\n",
       "      <td>有価証券報告書－第67期(平成28年9月1日－平成29年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BT1L</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30480</td>\n",
       "      <td>株式会社ビックカメラ</td>\n",
       "      <td>有価証券報告書－第37期(平成28年9月1日－平成29年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BT7H</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74450</td>\n",
       "      <td>株式会社ライトオン</td>\n",
       "      <td>有価証券報告書－第38期(平成28年8月21日－平成29年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BTBN</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>2017-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19970</td>\n",
       "      <td>暁飯島工業株式会社</td>\n",
       "      <td>有価証券報告書－第64期(平成28年9月1日－平成29年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BTH8</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>78700</td>\n",
       "      <td>福島印刷株式会社</td>\n",
       "      <td>有価証券報告書－第66期(平成29年8月21日－平成30年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100EJ7B</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>2018-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>75130</td>\n",
       "      <td>株式会社コジマ</td>\n",
       "      <td>有価証券報告書－第56期(平成29年9月1日－平成30年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100EL78</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>76070</td>\n",
       "      <td>株式会社進和</td>\n",
       "      <td>有価証券報告書－第68期(平成29年9月1日－平成30年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100ELFE</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>30480</td>\n",
       "      <td>株式会社ビックカメラ</td>\n",
       "      <td>有価証券報告書－第38期(平成29年9月1日－平成30年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100ELDC</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>74450</td>\n",
       "      <td>株式会社ライトオン</td>\n",
       "      <td>有価証券報告書－第39期(平成29年8月21日－平成30年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100ELD0</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>2018-08-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3671 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stkno          ID                                 Type  typecode  \\\n",
       "0     78700    福島印刷株式会社  有価証券報告書－第65期(平成28年8月21日－平成29年8月20日)       120   \n",
       "1     76070      株式会社進和   有価証券報告書－第67期(平成28年9月1日－平成29年8月31日)       120   \n",
       "2     30480  株式会社ビックカメラ   有価証券報告書－第37期(平成28年9月1日－平成29年8月31日)       120   \n",
       "3     74450   株式会社ライトオン  有価証券報告書－第38期(平成28年8月21日－平成29年8月20日)       120   \n",
       "4     19970   暁飯島工業株式会社   有価証券報告書－第64期(平成28年9月1日－平成29年8月31日)       120   \n",
       "...     ...         ...                                  ...       ...   \n",
       "3666  78700    福島印刷株式会社  有価証券報告書－第66期(平成29年8月21日－平成30年8月20日)       120   \n",
       "3667  75130     株式会社コジマ   有価証券報告書－第56期(平成29年9月1日－平成30年8月31日)       120   \n",
       "3668  76070      株式会社進和   有価証券報告書－第68期(平成29年9月1日－平成30年8月31日)       120   \n",
       "3669  30480  株式会社ビックカメラ   有価証券報告書－第38期(平成29年9月1日－平成30年8月31日)       120   \n",
       "3670  74450   株式会社ライトオン  有価証券報告書－第39期(平成29年8月21日－平成30年8月20日)       120   \n",
       "\n",
       "        Doc ID       start         end  \n",
       "0     S100BSAW  2016-08-21  2017-08-20  \n",
       "1     S100BT1L  2016-09-01  2017-08-31  \n",
       "2     S100BT7H  2016-09-01  2017-08-31  \n",
       "3     S100BTBN  2016-08-21  2017-08-20  \n",
       "4     S100BTH8  2016-09-01  2017-08-31  \n",
       "...        ...         ...         ...  \n",
       "3666  S100EJ7B  2017-08-21  2018-08-20  \n",
       "3667  S100EL78  2017-09-01  2018-08-31  \n",
       "3668  S100ELFE  2017-09-01  2018-08-31  \n",
       "3669  S100ELDC  2017-09-01  2018-08-31  \n",
       "3670  S100ELD0  2017-08-21  2018-08-20  \n",
       "\n",
       "[3671 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Set Time from 5 years ago to now\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "for i in years:\n",
    "    if i != 2022:\n",
    "        start_date = datetime.date(i,11,21)\n",
    "        end_date = datetime.date(i + 1, 11, 21)\n",
    "        #main(start_date,end_date)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b67c080",
   "metadata": {},
   "source": [
    "### 2. Extract Text Data from XBRL Files\n",
    "#### 2.1 Set up Text Intepreter: MeCab (with basic dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e7e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load Libraries\n",
    "!pip install edinet-xbrl -q\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from edinet_xbrl.edinet_xbrl_parser import EdinetXbrlParser\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7231263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Set up Mecab\n",
    "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
    "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
    "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
    "!pip install mecab-python3 > /dev/null\n",
    "!ln -s /etc/mecabrc /usr/local/etc/mecabrc\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e46b6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "To mount at Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "current_dir = '/content/drive/My Drive/textual analysis'\n",
    "import sys\n",
    "sys.path.append(current_dir)\n",
    "%cd $current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96710454",
   "metadata": {},
   "source": [
    "#### 2.2 Extract Text data from BusinessRisksText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61fb1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Filename_list(start_date,end_date):\n",
    "    start_year = start_date.year\n",
    "    end_year = end_date.year\n",
    "    path = '/content/drive/My Drive/thesis/Get XBRL/' + str(start_year) + '-' + str(end_year)\n",
    "    Filename_list = os.listdir(path)\n",
    "    for i in range(len(Filename_list)):\n",
    "        Filename_list[i] = Filename_list[i][:-4]\n",
    "\n",
    "    return Filename_list, path      # return a list of raw file identifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5224e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_textual_data(Filename,path):\n",
    "    path += '/' + Filename + '.zip'\n",
    "    try: \n",
    "        with zipfile.ZipFile(path,'r') as my_zip:\n",
    "            namelist = my_zip.namelist()\n",
    "            for i in range(len(namelist)):\n",
    "                if (namelist[i][-5:] == '.xbrl') & ('Audit' not in namelist[i]):\n",
    "                    target_file_dir = namelist[i]\n",
    "                    \n",
    "                    target_file = my_zip.extract(target_file_dir)          # Cause lots storage, to be investigated, create dir: /textual analysis/XBRL/Public doc/namelist[i] -> should add a path dir to specify the directory extracted to\n",
    "                    parser = EdinetXbrlParser()\n",
    "                    edinet_xbrl_object = parser.parse_file(target_file)\n",
    "                    key='jpcrp_cor:BusinessRisksTextBlock'\n",
    "                    context_ref='FilingDateInstant'\n",
    "                    data = edinet_xbrl_object.get_data_by_context_ref(key, context_ref)\n",
    "                    try:\n",
    "                        text_data = data.get_value()\n",
    "                    except AttributeError:\n",
    "                        text_data = 'Not Exist'\n",
    "\n",
    "    except zipfile.BadZipfile:\n",
    "        text_data = 'BadZipfile'\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be7bc7",
   "metadata": {},
   "source": [
    "#### 2.3 Cleanning Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdc9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanning_text(text_data):\n",
    "    with open(\"Japanese.txt\",\"r\") as f:\n",
    "        stopwords = f.read().split(\"\\n\")\n",
    "\n",
    "    text_data = re.sub('\\s','',text_data)\n",
    "    text_data = re.sub('<.*?>','',text_data)\n",
    "    cleanned_text = mecab_tokenizer(text_data)  # Use MeCab to Clean Text\n",
    "\n",
    "    return cleanned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587333e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_tokenizer(text):\n",
    "    # set up stopword\n",
    "    with open(\"Japanese.txt\",\"r\") as f:\n",
    "        stopwords = f.read().split(\"\\n\")\n",
    "\n",
    "        replaced_text = text.lower()\n",
    "        replaced_text = re.sub(r'[【】]', ' ', replaced_text)       # 【】の除去\n",
    "        replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
    "        replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
    "        replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "        replaced_text = re.sub(r'\\d+\\.*\\d*', '', replaced_text) #数字を0にする\n",
    "\n",
    "        mecab = MeCab.Tagger()\n",
    "        parsed_lines = mecab.parse(replaced_text).split(\"\\n\")[:-2]\n",
    "    \n",
    "        #表層形を取得\n",
    "        # surfaces = [l.split('\\t')[0] for l in parsed_lines]\n",
    "        #原形を取得\n",
    "        token_list = [l.split(\"\\t\")[1].split(\",\")[6] for l in parsed_lines]\n",
    "        #品詞を取得\n",
    "        pos = [l.split('\\t')[1].split(\",\")[0] for l in parsed_lines]\n",
    "        # 名詞,動詞,形容詞のみに絞り込み\n",
    "        target_pos = [\"名詞\",\"動詞\",\"形容詞\"]\n",
    "        token_list = [t for t, p in zip(token_list, pos) if p in target_pos]\n",
    "    \n",
    "        # stopwordsの除去\n",
    "        token_list = [t for t in token_list if t  not in stopwords]\n",
    "    \n",
    "        # ひらがなのみの単語を除く\n",
    "        kana_re = re.compile(\"^[ぁ-ゖ]+$\")\n",
    "        token_list = [t for t in token_list if not kana_re.match(t)]\n",
    "    \n",
    "    return ' '.join(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b63289",
   "metadata": {},
   "source": [
    "#### 2.4 Execute and View Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d8870f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stkno</th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>typecode</th>\n",
       "      <th>Doc ID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>clean text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78700</td>\n",
       "      <td>福島印刷株式会社</td>\n",
       "      <td>有価証券報告書－第65期(平成28年8月21日－平成29年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BSAW</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>事業 リスク 当社 事業 係る リスク 要因 可能 重要 事項 記載 文中 将来 事項 本書...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76070</td>\n",
       "      <td>株式会社進和</td>\n",
       "      <td>有価証券報告書－第67期(平成28年9月1日－平成29年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BT1L</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>事業 リスク 当社 グループ 経営 成績 財政 状態 影響 与える リスク 要因 可能 考え...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30480</td>\n",
       "      <td>株式会社ビックカメラ</td>\n",
       "      <td>有価証券報告書－第37期(平成28年9月1日－平成29年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BT7H</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74450</td>\n",
       "      <td>株式会社ライトオン</td>\n",
       "      <td>有価証券報告書－第38期(平成28年8月21日－平成29年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BTBN</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>事業 リスク 記載 事項 当社 事業 その他 リスク 投資 判断 重要 影響 及ぼす 可能 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19970</td>\n",
       "      <td>暁飯島工業株式会社</td>\n",
       "      <td>有価証券報告書－第64期(平成28年9月1日－平成29年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100BTH8</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>78700</td>\n",
       "      <td>福島印刷株式会社</td>\n",
       "      <td>有価証券報告書－第66期(平成29年8月21日－平成30年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100EJ7B</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>事業 リスク 当社 事業 係る リスク 要因 可能 重要 事項 記載 文中 将来 事項 本書...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>75130</td>\n",
       "      <td>株式会社コジマ</td>\n",
       "      <td>有価証券報告書－第56期(平成29年9月1日－平成30年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100EL78</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>76070</td>\n",
       "      <td>株式会社進和</td>\n",
       "      <td>有価証券報告書－第68期(平成29年9月1日－平成30年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100ELFE</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>事業 リスク 当社 グループ 経営 成績 財政 状態 影響 与える リスク 要因 可能 考え...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>30480</td>\n",
       "      <td>株式会社ビックカメラ</td>\n",
       "      <td>有価証券報告書－第38期(平成29年9月1日－平成30年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100ELDC</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>74450</td>\n",
       "      <td>株式会社ライトオン</td>\n",
       "      <td>有価証券報告書－第39期(平成29年8月21日－平成30年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100ELD0</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>事業 リスク 記載 事項 当社 グループ 事業 その他 リスク 投資 判断 重要 影響 及ぼ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3671 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stkno          ID                                 Type  typecode  \\\n",
       "0     78700    福島印刷株式会社  有価証券報告書－第65期(平成28年8月21日－平成29年8月20日)       120   \n",
       "1     76070      株式会社進和   有価証券報告書－第67期(平成28年9月1日－平成29年8月31日)       120   \n",
       "2     30480  株式会社ビックカメラ   有価証券報告書－第37期(平成28年9月1日－平成29年8月31日)       120   \n",
       "3     74450   株式会社ライトオン  有価証券報告書－第38期(平成28年8月21日－平成29年8月20日)       120   \n",
       "4     19970   暁飯島工業株式会社   有価証券報告書－第64期(平成28年9月1日－平成29年8月31日)       120   \n",
       "...     ...         ...                                  ...       ...   \n",
       "3666  78700    福島印刷株式会社  有価証券報告書－第66期(平成29年8月21日－平成30年8月20日)       120   \n",
       "3667  75130     株式会社コジマ   有価証券報告書－第56期(平成29年9月1日－平成30年8月31日)       120   \n",
       "3668  76070      株式会社進和   有価証券報告書－第68期(平成29年9月1日－平成30年8月31日)       120   \n",
       "3669  30480  株式会社ビックカメラ   有価証券報告書－第38期(平成29年9月1日－平成30年8月31日)       120   \n",
       "3670  74450   株式会社ライトオン  有価証券報告書－第39期(平成29年8月21日－平成30年8月20日)       120   \n",
       "\n",
       "        Doc ID       start         end  \\\n",
       "0     S100BSAW  2016-08-21  2017-08-20   \n",
       "1     S100BT1L  2016-09-01  2017-08-31   \n",
       "2     S100BT7H  2016-09-01  2017-08-31   \n",
       "3     S100BTBN  2016-08-21  2017-08-20   \n",
       "4     S100BTH8  2016-09-01  2017-08-31   \n",
       "...        ...         ...         ...   \n",
       "3666  S100EJ7B  2017-08-21  2018-08-20   \n",
       "3667  S100EL78  2017-09-01  2018-08-31   \n",
       "3668  S100ELFE  2017-09-01  2018-08-31   \n",
       "3669  S100ELDC  2017-09-01  2018-08-31   \n",
       "3670  S100ELD0  2017-08-21  2018-08-20   \n",
       "\n",
       "                                             clean text  \n",
       "0     事業 リスク 当社 事業 係る リスク 要因 可能 重要 事項 記載 文中 将来 事項 本書...  \n",
       "1     事業 リスク 当社 グループ 経営 成績 財政 状態 影響 与える リスク 要因 可能 考え...  \n",
       "2     事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...  \n",
       "3     事業 リスク 記載 事項 当社 事業 その他 リスク 投資 判断 重要 影響 及ぼす 可能 ...  \n",
       "4     事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...  \n",
       "...                                                 ...  \n",
       "3666  事業 リスク 当社 事業 係る リスク 要因 可能 重要 事項 記載 文中 将来 事項 本書...  \n",
       "3667  事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...  \n",
       "3668  事業 リスク 当社 グループ 経営 成績 財政 状態 影響 与える リスク 要因 可能 考え...  \n",
       "3669  事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 ...  \n",
       "3670  事業 リスク 記載 事項 当社 グループ 事業 その他 リスク 投資 判断 重要 影響 及ぼ...  \n",
       "\n",
       "[3671 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_list = [2017,2018,2019,2020,2021,2022]\n",
    "for i in year_list:\n",
    "    if i != 2022:\n",
    "        start_date = datetime.date(i,11,22)\n",
    "        end_date = datetime.date(i+1,11,22)\n",
    "        identifier = str(i)+ '-' + str(i+1)\n",
    "        path = '/content/drive/My Drive/thesis/Get XBRL/' + identifier + '.csv'\n",
    "        save_path = '/content/drive/My Drive/thesis/Get XBRL/' + identifier + 'cleaned_text.csv'\n",
    "\n",
    "        XBRL_text = pd.read_csv(path)\n",
    "        copy = XBRL_text['Doc ID'].tolist()\n",
    "        XBRL_text['clean text'] = copy\n",
    "\n",
    "        Filename_list,path = get_Filename_list(start_date,end_date)\n",
    "        count = 1\n",
    "        for i in Filename_list:\n",
    "            print(count,\"/\",len(Filename_list))\n",
    "            count += 1 \n",
    "            text_data = get_textual_data(i,path)\n",
    "            if text_data == 'BadZipfile':\n",
    "                cleanned_text = 'BadZipfile'\n",
    "                elif text_data == 'Not Exist': \n",
    "                    cleanned_text = 'Not Exist'\n",
    "                else:\n",
    "                    cleanned_text = cleanning_text(text_data)\n",
    "            XBRL_text['clean text'] = XBRL_text['clean text'].replace(i,cleanned_text)\n",
    "        XBRL_text.to_csv(save_path)\n",
    "        print(f'period {start_date.year} to {end_date.year} is finished')\n",
    "    else:\n",
    "        print('processing finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5a9d5",
   "metadata": {},
   "source": [
    "### 3. Calculate Stickiness Score and Export to Stata\n",
    "#### 3.1 Merge year-level Data into one Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79cf4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_df(start_year,end_year):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(start_year,end_year):\n",
    "        path = '/content/drive/My Drive/thesis/Get XBRL/' + str(i) + '-' + str(i+1) + 'cleaned_text.csv'\n",
    "        df_append = pd.read_csv(path,index_col=[0])\n",
    "        df = df.append(df_append,ignore_index= True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b5d9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text_dataframe):\n",
    "    copy = text_dataframe['Doc ID'].tolist()\n",
    "    text_dataframe['year'] = copy\n",
    "    text_dataframe['score'] = copy\n",
    "\n",
    "    bad_text_count = 1\n",
    "    for ind in text_dataframe.index:\n",
    "        if text_dataframe['clean text'][ind] in ['BadZipfile','Not Exist']:\n",
    "            print(f\"count: {bad_text_count}\")\n",
    "            bad_text_count += 1\n",
    "            text_dataframe.drop(ind)\n",
    "\n",
    "    for ind in text_dataframe.index:\n",
    "        end_year = text_dataframe['end'][ind]\n",
    "        year_identifier = datetime.datetime.strptime(end_year, '%Y-%m-%d').date()\n",
    "    \n",
    "        if year_identifier >= datetime.date(year_identifier.year,1,1):\n",
    "            text_dataframe.at[ind,'year'] = year_identifier.year\n",
    "        else:\n",
    "            text_dataframe.at[ind,'year'] = year_identifier.year-1\n",
    "\n",
    "    return text_dataframe  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786350ec",
   "metadata": {},
   "source": [
    "#### 3.2 Define and Calculate Stickiness Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43657bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_text(text_dataframe):\n",
    "    for ind in text_dataframe.index:\n",
    "        text_dataframe.at[ind,'unique'] = len(text_dataframe['clean text'][ind].split())\n",
    "\n",
    "    group_index = set(text_dataframe['stkno'].tolist())\n",
    "    print(f\"There are {len(group_index)} firms out of {len(text_dataframe['stkno'].tolist())} obs\")\n",
    "    \n",
    "    for i in group_index:\n",
    "        compare_df = text_dataframe.loc[text_dataframe['stkno'] == i]\n",
    "        if len(compare_df.index) <= 1:\n",
    "            text_dataframe = text_dataframe.drop(compare_df.index)\n",
    "        else:\n",
    "            for i in range(len(compare_df.index)-1):\n",
    "                target_index = compare_df.index[i+1]\n",
    "                years_before = compare_df['clean text'][compare_df.index[i]].split()\n",
    "                years_after = compare_df['clean text'][compare_df.index[i+1]].split()\n",
    "                count = 0\n",
    "\n",
    "                base = len(years_before)\n",
    "                for k in years_after:\n",
    "                    if k in years_before:\n",
    "                        count += 1\n",
    "                sticky_score = count/base\n",
    "                text_dataframe.at[target_index,'sticky_count'] = count\n",
    "                text_dataframe.at[target_index,'sticky_ratio'] = sticky_score\n",
    "                print(count,sticky_score)\n",
    "            text_dataframe = text_dataframe.drop(compare_df.index[0])\n",
    "    return text_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c33cd8",
   "metadata": {},
   "source": [
    "#### 3.3  Export to Stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f73265a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_stata(final_df):\n",
    "    stata_df = final_df.drop(columns=['clean text','Unnamed: 0.1'])\n",
    "    convert_list_int = ['unique','sticky_count','sticky_ratio']\n",
    "    stata_df[convert_list_int] = stata_df[convert_list_int].astype(float)        #To change object to float class\n",
    "    convert_list_str = list(stata_df.select_dtypes(include=['object']).columns)  # list others in object class\n",
    "    stata_df[convert_list_str] = stata_df[convert_list_str].astype(str)\n",
    "    stata_df.to_stata('/content/drive/My Drive/thesis/Get XBRL/text_data.dta',write_index= False,version=118)\n",
    "    print('stata file saved')\n",
    "    return stata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147d1fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>stkno</th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>typecode</th>\n",
       "      <th>Doc ID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>clean text</th>\n",
       "      <th>year</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2297</td>\n",
       "      <td>2297</td>\n",
       "      <td>13840</td>\n",
       "      <td>株式会社　ホクリヨウ</td>\n",
       "      <td>有価証券報告書－第70期(平成29年9月1日－平成30年3月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100DG58</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>事業 リスク 当社 グループ 事業 状況 経理 状況 事項 リスク 要因 可能 考える 主 ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.939151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3189</td>\n",
       "      <td>3189</td>\n",
       "      <td>17800</td>\n",
       "      <td>株式会社　ヤマウラ</td>\n",
       "      <td>有価証券報告書－第59期(平成29年10月1日－平成30年3月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100DIB6</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>事業 リスク グループ 経営 成績 財務 状態 株価 影響 及ぼす 可能 事項 文中 将来 ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.991667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3496</td>\n",
       "      <td>3496</td>\n",
       "      <td>99420</td>\n",
       "      <td>株式会社ジョイフル</td>\n",
       "      <td>有価証券報告書－第44期(平成30年1月1日－平成30年6月30日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100E2S2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>BadZipfile</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>78700</td>\n",
       "      <td>福島印刷株式会社</td>\n",
       "      <td>有価証券報告書－第66期(平成29年8月21日－平成30年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100EJ7B</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>事業 リスク 当社 事業 係る リスク 要因 可能 重要 事項 記載 文中 将来 事項 本書...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.996753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3668</td>\n",
       "      <td>3668</td>\n",
       "      <td>76070</td>\n",
       "      <td>株式会社進和</td>\n",
       "      <td>有価証券報告書－第68期(平成29年9月1日－平成30年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100ELFE</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>事業 リスク 当社 グループ 経営 成績 財政 状態 影響 与える リスク 要因 可能 考え...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14862</th>\n",
       "      <td>18948</td>\n",
       "      <td>3873</td>\n",
       "      <td>49340</td>\n",
       "      <td>プレミアアンチエイジング株式会社</td>\n",
       "      <td>有価証券報告書－第13期(令和3年8月1日－令和4年7月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100PFLO</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>事業 リスク 本書 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 及ぼす 可能...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.014041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14863</th>\n",
       "      <td>18949</td>\n",
       "      <td>3874</td>\n",
       "      <td>29910</td>\n",
       "      <td>株式会社ランドネット</td>\n",
       "      <td>有価証券報告書－第23期(令和3年8月1日－令和4年7月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100PFK7</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 連結 会社 財政 ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.965344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14864</th>\n",
       "      <td>18950</td>\n",
       "      <td>3875</td>\n",
       "      <td>76820</td>\n",
       "      <td>株式会社浜木綿</td>\n",
       "      <td>有価証券報告書－第55期(令和3年8月1日－令和4年7月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100PFNI</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 財政 状態 経営 ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.895695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14865</th>\n",
       "      <td>18951</td>\n",
       "      <td>3876</td>\n",
       "      <td>30350</td>\n",
       "      <td>ケイティケイ株式会社</td>\n",
       "      <td>有価証券報告書－第51期(令和3年8月21日－令和4年8月20日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100PI4C</td>\n",
       "      <td>2021-08-21</td>\n",
       "      <td>2022-08-20</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 連結 会社 財政 ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.047821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14866</th>\n",
       "      <td>18952</td>\n",
       "      <td>3877</td>\n",
       "      <td>94140</td>\n",
       "      <td>日本ＢＳ放送株式会社</td>\n",
       "      <td>有価証券報告書－第24期(令和3年9月1日－令和4年8月31日)</td>\n",
       "      <td>120</td>\n",
       "      <td>S100PNF1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 連結 会社 財政 ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.945894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14867 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  stkno                ID  \\\n",
       "0            2297          2297  13840        株式会社　ホクリヨウ   \n",
       "1            3189          3189  17800         株式会社　ヤマウラ   \n",
       "2            3496          3496  99420         株式会社ジョイフル   \n",
       "3            3666          3666  78700          福島印刷株式会社   \n",
       "4            3668          3668  76070            株式会社進和   \n",
       "...           ...           ...    ...               ...   \n",
       "14862       18948          3873  49340  プレミアアンチエイジング株式会社   \n",
       "14863       18949          3874  29910        株式会社ランドネット   \n",
       "14864       18950          3875  76820           株式会社浜木綿   \n",
       "14865       18951          3876  30350        ケイティケイ株式会社   \n",
       "14866       18952          3877  94140        日本ＢＳ放送株式会社   \n",
       "\n",
       "                                      Type  typecode    Doc ID       start  \\\n",
       "0       有価証券報告書－第70期(平成29年9月1日－平成30年3月31日)       120  S100DG58  2017-09-01   \n",
       "1      有価証券報告書－第59期(平成29年10月1日－平成30年3月31日)       120  S100DIB6  2017-10-01   \n",
       "2       有価証券報告書－第44期(平成30年1月1日－平成30年6月30日)       120  S100E2S2  2018-01-01   \n",
       "3      有価証券報告書－第66期(平成29年8月21日－平成30年8月20日)       120  S100EJ7B  2017-08-21   \n",
       "4       有価証券報告書－第68期(平成29年9月1日－平成30年8月31日)       120  S100ELFE  2017-09-01   \n",
       "...                                    ...       ...       ...         ...   \n",
       "14862     有価証券報告書－第13期(令和3年8月1日－令和4年7月31日)       120  S100PFLO  2021-08-01   \n",
       "14863     有価証券報告書－第23期(令和3年8月1日－令和4年7月31日)       120  S100PFK7  2021-08-01   \n",
       "14864     有価証券報告書－第55期(令和3年8月1日－令和4年7月31日)       120  S100PFNI  2021-08-01   \n",
       "14865    有価証券報告書－第51期(令和3年8月21日－令和4年8月20日)       120  S100PI4C  2021-08-21   \n",
       "14866     有価証券報告書－第24期(令和3年9月1日－令和4年8月31日)       120  S100PNF1  2021-09-01   \n",
       "\n",
       "              end                                         clean text  year  \\\n",
       "0      2018-03-31  事業 リスク 当社 グループ 事業 状況 経理 状況 事項 リスク 要因 可能 考える 主 ...  2018   \n",
       "1      2018-03-31  事業 リスク グループ 経営 成績 財務 状態 株価 影響 及ぼす 可能 事項 文中 将来 ...  2018   \n",
       "2      2018-06-30                                         BadZipfile  2018   \n",
       "3      2018-08-20  事業 リスク 当社 事業 係る リスク 要因 可能 重要 事項 記載 文中 将来 事項 本書...  2018   \n",
       "4      2018-08-31  事業 リスク 当社 グループ 経営 成績 財政 状態 影響 与える リスク 要因 可能 考え...  2018   \n",
       "...           ...                                                ...   ...   \n",
       "14862  2022-07-31  事業 リスク 本書 記載 事業 状況 経理 状況 事項 投資 判断 重要 影響 及ぼす 可能...  2022   \n",
       "14863  2022-07-31  事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 連結 会社 財政 ...  2022   \n",
       "14864  2022-07-31  事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 財政 状態 経営 ...  2022   \n",
       "14865  2022-08-20  事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 連結 会社 財政 ...  2022   \n",
       "14866  2022-08-31  事業 リスク 有価 証券 報告 記載 事業 状況 経理 状況 事項 経営 連結 会社 財政 ...  2022   \n",
       "\n",
       "          score  \n",
       "0      0.939151  \n",
       "1      0.991667  \n",
       "2      0.000000  \n",
       "3      0.996753  \n",
       "4      1.000000  \n",
       "...         ...  \n",
       "14862  1.014041  \n",
       "14863  0.965344  \n",
       "14864  0.895695  \n",
       "14865  1.047821  \n",
       "14866  0.945894  \n",
       "\n",
       "[14867 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combine_text_df(2017,2022)\n",
    "prepared_df = prepare_text(combined_df)\n",
    "final_df = compare_text(prepared_df)\n",
    "stata_df = save_as_stata(final_df)        #To save as stata files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6d925",
   "metadata": {},
   "source": [
    "### 4. Process and Report via Stata  \n",
    "#### 4.1 Import Stata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2058a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ___  ____  ____  ____  ____ ©\n",
      " /__    /   ____/   /   ____/      17.0\n",
      "___/   /   /___/   /   /___/       SE—Standard Edition\n",
      "\n",
      " Statistics and Data Science       Copyright 1985-2021 StataCorp LLC\n",
      "                                   StataCorp\n",
      "                                   4905 Lakeway Drive\n",
      "                                   College Station, Texas 77845 USA\n",
      "                                   800-STATA-PC        https://www.stata.com\n",
      "                                   979-696-4600        stata@stata.com\n",
      "\n",
      "Stata license: 100-student lab perpetual\n",
      "Serial number: 401706316154\n",
      "  Licensed to: Medjed\n",
      "               \n",
      "\n",
      "Notes:\n",
      "      1. Unicode is supported; see help unicode_advice.\n",
      "      2. Maximum number of variables is set to 5,000; see help set_maxvar.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:/Stata 17/utilities\")\n",
    "from pystata import config\n",
    "config.init(\"se\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda40743",
   "metadata": {},
   "source": [
    "#### 4.2 Processing and Display Textual-Related Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bca3d22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ". *Import Data\n",
      ". use \"D:\\Study\\Data\\gdrive_XBRL\\text_data2.dta\" \n",
      "\n",
      ". \n",
      ". *To trim on 1-99 percentile\n",
      ". winsor2 unique ,replace cut(1 99) trim\n",
      "\n",
      ". sum unique sticky_count sticky_ratio,detail\n",
      "\n",
      "                           unique\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%          182            134\n",
      " 5%          262            134\n",
      "10%          326            135       Obs              14,571\n",
      "25%          482            135       Sum of wgt.      14,571\n",
      "\n",
      "50%          773                      Mean           910.7787\n",
      "                        Largest       Std. dev.      579.1233\n",
      "75%         1198           3764\n",
      "90%         1654           3766       Variance       335383.8\n",
      "95%         1997           3767       Skewness         1.4707\n",
      "99%         2961           3785       Kurtosis       5.904593\n",
      "\n",
      "                        sticky_count\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%          110              0\n",
      " 5%          218              0\n",
      "10%          284              0       Obs              14,867\n",
      "25%          431              0       Sum of wgt.      14,867\n",
      "\n",
      "50%          706                      Mean           881.6744\n",
      "                        Largest       Std. dev.       720.491\n",
      "75%         1135          10685\n",
      "90%         1609          12897       Variance       519107.3\n",
      "95%         2001          14422       Skewness       4.104017\n",
      "99%         3629          16086       Kurtosis       44.37439\n",
      "\n",
      "                        sticky_ratio\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     .4387879              0\n",
      " 5%     .6735537              0\n",
      "10%     .7783019              0       Obs              14,867\n",
      "25%     .9169435              0       Sum of wgt.      14,867\n",
      "\n",
      "50%     .9791667                      Mean           .9278302\n",
      "                        Largest       Std. dev.      .1252323\n",
      "75%     .9985915              1\n",
      "90%            1              1       Variance       .0156831\n",
      "95%            1              1       Skewness       -3.32385\n",
      "99%            1              1       Kurtosis       18.44455\n",
      "\n",
      ". drop if unique == .\n",
      "(296 observations deleted)\n",
      "\n",
      ". drop if sticky_count == .\n",
      "(0 observations deleted)\n",
      "\n",
      ". drop if sticky_ratio == .\n",
      "(0 observations deleted)\n",
      "\n",
      ". \n",
      ". label variable unique \"unique words in risk disclosure\"\n",
      "\n",
      ". label variable sticky_count \"sticky words in risk disclosure\"\n",
      "\n",
      ". label variable sticky_ratio \"stickiness measure\" \n",
      "\n",
      ". \n",
      ". *To see if unique words is normally distributed\n",
      ". gen log_unique = log(unique)\n",
      "\n",
      ". *histogram log_unique , freq normal kdensity\n",
      ". \n",
      ". *Simple test\n",
      ". ttest sticky_ratio == 0\n",
      "\n",
      "One-sample t test\n",
      "------------------------------------------------------------------------------\n",
      "Variable |     Obs        Mean    Std. err.   Std. dev.   [95% conf. interval]\n",
      "---------+--------------------------------------------------------------------\n",
      "sticky~o |  14,571    .9284868    .0010023     .120982    .9265223    .9304514\n",
      "------------------------------------------------------------------------------\n",
      "    mean = mean(sticky_ratio)                                     t = 926.4021\n",
      "H0: mean = 0                                     Degrees of freedom =    14570\n",
      "\n",
      "    Ha: mean < 0                 Ha: mean != 0                 Ha: mean > 0\n",
      " Pr(T < t) = 1.0000         Pr(|T| > |t|) = 0.0000          Pr(T > t) = 0.0000\n",
      "\n",
      ". \n",
      ". *Delete duplicates\n",
      ". duplicates report stkno year\n",
      "\n",
      "Duplicates in terms of stkno year\n",
      "\n",
      "--------------------------------------\n",
      "   Copies | Observations       Surplus\n",
      "----------+---------------------------\n",
      "        1 |        14453             0\n",
      "        2 |          118            59\n",
      "--------------------------------------\n",
      "\n",
      ". duplicates tag stkno year , gen(isdup)\n",
      "\n",
      "Duplicates in terms of stkno year\n",
      "\n",
      ". sum isdup,detail\n",
      "\n",
      "                            isdup\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%            0              0\n",
      " 5%            0              0\n",
      "10%            0              0       Obs              14,571\n",
      "25%            0              0       Sum of wgt.      14,571\n",
      "\n",
      "50%            0                      Mean           .0080983\n",
      "                        Largest       Std. dev.      .0896284\n",
      "75%            0              1\n",
      "90%            0              1       Variance       .0080332\n",
      "95%            0              1       Skewness       10.97685\n",
      "99%            0              1       Kurtosis       121.4912\n",
      "\n",
      ". drop if isdup == 1    // (118 observations deleted)\n",
      "(118 observations deleted)\n",
      "\n",
      ". \n",
      ". *Set times \n",
      ". gen year_d = yearly(substr( year ,1,4), \"Y\")\n",
      "\n",
      ". format year_d %ty\n",
      "\n",
      ". xtset stkno year_d     // repeated time values within panel\n",
      "\n",
      "Panel variable: stkno (unbalanced)\n",
      " Time variable: year_d, 2018 to 2022, but with gaps\n",
      "         Delta: 1 year\n",
      "\n",
      ". \n",
      ". by year, sort: sum unique sticky_count sticky_ratio\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "-> year = 2018\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      unique |        704    842.2486    550.1451        135       3554\n",
      "sticky_count |        704    821.6023    539.7271        119       3547\n",
      "sticky_ratio |        704    .9760587    .0575864   .5417722          1\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "-> year = 2019\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      unique |      3,555    730.7395    520.0285        134       3690\n",
      "sticky_count |      3,555     706.452    509.3384          0       3562\n",
      "sticky_ratio |      3,555    .9677412    .1021721          0          1\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "-> year = 2020\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      unique |      3,648    936.0998    564.3956        138       3764\n",
      "sticky_count |      3,648    791.7308    531.2176          0       3676\n",
      "sticky_ratio |      3,648    .8295132    .1476115          0          1\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "-> year = 2021\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      unique |      3,683    992.2129    586.2736        138       3767\n",
      "sticky_count |      3,683     947.038    569.4164          0       3732\n",
      "sticky_ratio |      3,683    .9542067    .0836246          0          1\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "-> year = 2022\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "      unique |      2,863    1006.933    606.1877        138       3785\n",
      "sticky_count |      2,863    963.1593    580.7972          0       3735\n",
      "sticky_ratio |      2,863     .961077    .0805719          0          1\n",
      "\n",
      "\n",
      ". egen mean_unique =mean( unique), by(year)\n",
      "\n",
      ". egen mean_sticky_count  =mean( sticky_count ), by(year)\n",
      "\n",
      ". egen mean_sticky_ratio =mean( sticky_ratio), by(year)\n",
      "\n",
      ". *twoway (tsline mean_unique  mean_sticky_count) (tsline mean_sticky_ratio,yax\n",
      "> is(2)), ///\n",
      "> *title(\"Change in Risk Disclosure Stickiness\") subtitle(\"from 2018 to 2022\") \n",
      "> ///\n",
      "> *ytitle(\"Words Count\")  ytitle(\"Score\", axis(2)) ///\n",
      "> *note(\"Source: Annual Reports from EDINET API\") ///\n",
      "> *legend(order(1 \"Unique Words\" 2 \"Sticky Words\" 3 \"Stickiness Score\")) ///\n",
      "> *scheme(s2mono) saving(D:/Study/研究/myfig.gph, replace)\n",
      ". *graph export \"D:\\Study\\研究\\myfig.jpg\", as(emf) name(\"Graph\") replace\n",
      ". \n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "*Import Data\n",
    "use \"D:\\Study\\Data\\gdrive_XBRL\\text_data2.dta\" \n",
    "\n",
    "*To trim on 1-99 percentile\n",
    "winsor2 unique ,replace cut(1 99) trim\n",
    "sum unique sticky_count sticky_ratio,detail\n",
    "drop if unique == .\n",
    "drop if sticky_count == .\n",
    "drop if sticky_ratio == .\n",
    "\n",
    "label variable unique \"unique words in risk disclosure\"\n",
    "label variable sticky_count \"sticky words in risk disclosure\"\n",
    "label variable sticky_ratio \"stickiness measure\" \n",
    "\n",
    "*To see if unique words is normally distributed\n",
    "gen log_unique = log(unique)\n",
    "*histogram log_unique , freq normal kdensity\n",
    "\n",
    "*Simple test\n",
    "ttest sticky_ratio == 0\n",
    "\n",
    "*Delete duplicates\n",
    "duplicates report stkno year\n",
    "duplicates tag stkno year , gen(isdup)\n",
    "sum isdup,detail\n",
    "drop if isdup == 1    // (118 observations deleted)\n",
    "\n",
    "*Set times \n",
    "gen year_d = yearly(substr( year ,1,4), \"Y\")\n",
    "format year_d %ty\n",
    "xtset stkno year_d     // repeated time values within panel\n",
    "\n",
    "by year, sort: sum unique sticky_count sticky_ratio\n",
    "egen mean_unique =mean( unique), by(year)\n",
    "egen mean_sticky_count  =mean( sticky_count ), by(year)\n",
    "egen mean_sticky_ratio =mean( sticky_ratio), by(year)\n",
    "*twoway (tsline mean_unique  mean_sticky_count) (tsline mean_sticky_ratio,yaxis(2)), ///\n",
    "*title(\"Change in Risk Disclosure Stickiness\") subtitle(\"from 2018 to 2022\") ///\n",
    "*ytitle(\"Words Count\")  ytitle(\"Score\", axis(2)) ///\n",
    "*note(\"Source: Annual Reports from EDINET API\") ///\n",
    "*legend(order(1 \"Unique Words\" 2 \"Sticky Words\" 3 \"Stickiness Score\")) ///\n",
    "*scheme(s2mono) saving(D:/Study/研究/myfig.gph, replace)\n",
    "*graph export \"D:\\Study\\研究\\myfig.jpg\", as(emf) name(\"Graph\") replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bc3d5",
   "metadata": {},
   "source": [
    "#### 4.3 Merge with Financial Data and Conduct Simple Statistical Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3100e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". clear\n",
      "\n",
      "\n",
      ". use \"D:\\Study\\Data\\data_2022_new\\financial_data\\FSdata20220920.dta\"\n",
      "\n",
      ". \n",
      ". *Drop useless items\n",
      ". drop if stkno == 9999    //Not existing stock code\n",
      "(111,385 observations deleted)\n",
      "\n",
      ". drop if macc != 12       //Accounting Period not equal to 12\n",
      "(16,681 observations deleted)\n",
      "\n",
      ". *Keep Consolidated Items (scflg==2) in duplicates group \n",
      ". sort stkno acc\n",
      "\n",
      ". by stkno acc: gen isdup = cond(_N == 1 | (_N != 1 & a01_scflg == 2), 0,1)\n",
      "\n",
      ". drop if isdup == 1       //However, it will remain some duplicates\n",
      "(70,266 observations deleted)\n",
      "\n",
      ". drop isdup\n",
      "\n",
      ". \n",
      ". *To set time\n",
      ". tostring acc, generate(date)\n",
      "date generated as str6\n",
      "\n",
      ". gen year = yearly(substr(date,1,4), \"Y\")   // to extract year from YYYYMM for\n",
      "> mat data\n",
      "\n",
      ". format year %ty\n",
      "\n",
      ". duplicates report stkno year\n",
      "\n",
      "Duplicates in terms of stkno year\n",
      "\n",
      "--------------------------------------\n",
      "   Copies | Observations       Surplus\n",
      "----------+---------------------------\n",
      "        1 |       110246             0\n",
      "        2 |          802           401\n",
      "--------------------------------------\n",
      "\n",
      ". duplicates tag stkno year , gen(isdup)\n",
      "\n",
      "Duplicates in terms of stkno year\n",
      "\n",
      ". drop if isdup == 1\n",
      "(802 observations deleted)\n",
      "\n",
      ". tab isdup\n",
      "\n",
      "      isdup |      Freq.     Percent        Cum.\n",
      "------------+-----------------------------------\n",
      "          0 |    110,246      100.00      100.00\n",
      "------------+-----------------------------------\n",
      "      Total |    110,246      100.00\n",
      "\n",
      ". xtset stkno year\n",
      "\n",
      "Panel variable: stkno (unbalanced)\n",
      " Time variable: year, 1964 to 2021, but with gaps\n",
      "         Delta: 1 year\n",
      "\n",
      ". drop date\n",
      "\n",
      ". \n",
      ". *Sort Variables \n",
      ". clonevar Assets = b01110\n",
      "(47 missing values generated)\n",
      "\n",
      ". clonevar Liabilities = c01082\n",
      "(49 missing values generated)\n",
      "\n",
      ". clonevar Net_Assets = c01083\n",
      "(61,821 missing values generated)\n",
      "\n",
      ". clonevar cfo = f01065\n",
      "(45,288 missing values generated)\n",
      "\n",
      ". clonevar sales = d01021\n",
      "(83 missing values generated)\n",
      "\n",
      ". clonevar Net_Income = d01114\n",
      "(80,112 missing values generated)\n",
      "\n",
      ". drop if missing(Assets,Liabilities,Net_Assets,cfo,sales, Net_Income,da_mj) \n",
      "(84,939 observations deleted)\n",
      "\n",
      ". \n",
      ". gen ln_Assets = log(Assets)    \n",
      "\n",
      ". gen Leverage_Ratio = Liabilities/Net_Assets     \n",
      "\n",
      ". gen ROA = Net_Income/Assets    \n",
      "\n",
      ". keep stkno ename ntcls nkil year Assets Liabilities Net_Assets  cfo  sales Ne\n",
      "> t_Income  ln_Assets  Leverage_Ratio ROA da_mj\n",
      "\n",
      ". \n",
      ". *Merge Dataset\n",
      ". merge 1:1 stkno year using \"D:\\Study\\Data\\gdrive_XBRL\\text_data_formerge.dta\"\n",
      "\n",
      "    Result                      Number of obs\n",
      "    -----------------------------------------\n",
      "    Not matched                        24,942\n",
      "        from master                    17,898  (_merge==1)\n",
      "        from using                      7,044  (_merge==2)\n",
      "\n",
      "    Matched                             7,409  (_merge==3)\n",
      "    -----------------------------------------\n",
      "\n",
      ". drop if _merge == 1 | _merge == 2\n",
      "(24,942 observations deleted)\n",
      "\n",
      ". \n",
      ". *Generate Variables for Regression\n",
      ". gen ln_Length = log(unique)\n",
      "\n",
      ". gen ln_sticky_count = log(sticky_count)\n",
      "(18 missing values generated)\n",
      "\n",
      ". drop if missing(ln_Length,ln_sticky_count,sticky_ratio)\n",
      "(18 observations deleted)\n",
      "\n",
      ". winsor2 ln_sticky_count sticky_ratio ln_Assets Leverage_Ratio ROA da_mj,repla\n",
      "> ce cut(1 99)\n",
      "\n",
      ". winsor2 Net_Assets cfo sales,replace cut(5 95) // Cut others for outreg table\n",
      "> s\n",
      "\n",
      ". \n",
      ". *Generate Industry Identifier\n",
      ". tostring nkil, generate(nkil_str)\n",
      "nkil_str generated as str6\n",
      "\n",
      ". gen middle_nkil = substr(nkil_str,1,2)\n",
      "\n",
      ". egen industry_code = group(middle_nkil)\n",
      "\n",
      ". codebook middle_nkil                // check the industry code of each group\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "middle_nkil                                                         (unlabeled)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "                  Type: String (str2)\n",
      "\n",
      "         Unique values: 8                         Missing \"\": 0/7,391\n",
      "\n",
      "            Tabulation: Freq.  Value\n",
      "                        1,078  \"10\"\n",
      "                          589  \"11\"\n",
      "                        1,391  \"12\"\n",
      "                          379  \"13\"\n",
      "                        1,720  \"24\"\n",
      "                          431  \"25\"\n",
      "                          153  \"26\"\n",
      "                        1,650  \"27\"\n",
      "\n",
      ". egen mean_sticky_ratio  =mean(sticky_ratio), by(year middle_nkil)\n",
      "\n",
      ". \n",
      ". *Export decriptive data to word files\n",
      ". *outreg2 using descriptive.doc,replace sum(log) keep(unique sticky_count stic\n",
      "> ky_ratio ln_Assets Leverage_Ratio ROA Net_Assets cfo sales) \n",
      ". \n",
      ". *Creating Graph Using Industry Identifier \n",
      ". *Problem: the codebook does not include mid-code like \"11\", \"24\",\"25, etc\n",
      ". *twoway (tsline mean_sticky_ratio if middle_nkil == \"11\") (tsline mean_sticky\n",
      "> _ratio if middle_nkil == \"13\") ///  \n",
      "> *(tsline mean_sticky_ratio if middle_nkil == \"25\")  (tsline mean_sticky_ratio\n",
      ">  if middle_nkil == \"27\"), /// \n",
      "> *legend(order(1 \"石油\" 2 \"ゴム\" 3 \"造船\" 4 \"自動車\")) /// \n",
      "> *title(\"Stickiness Score by Industry\") subtitle(\"from 2018 to 2022\") /// \n",
      "> *ytitle(\"Score\")  /// \n",
      "> *note(\"Source: Annual Reports from EDINET API\") /// \n",
      "> *scheme(s2mono) saving(D:/Study/研究/Sticksore_by_industry.gph, replace) /// \n",
      "> *graph export \"D:\\Study\\研究\\Sticksore_by_industry.jpg\", as(emf) name(\"Graph\"\n",
      "> ) replace\n",
      ". \n",
      ". *Export using esttout \n",
      ". eststo clear\n",
      "\n",
      ". eststo:xtreg ln_sticky_count ln_Assets Leverage_Ratio ROA  ln_Length, fe\n",
      "\n",
      "Fixed-effects (within) regression               Number of obs     =      7,391\n",
      "Group variable: stkno                           Number of groups  =      2,677\n",
      "\n",
      "R-squared:                                      Obs per group:\n",
      "     Within  = 0.7057                                         min =          1\n",
      "     Between = 0.7399                                         avg =        2.8\n",
      "     Overall = 0.7402                                         max =          3\n",
      "\n",
      "                                                F(4,4710)         =    2823.23\n",
      "corr(u_i, Xb) = 0.0531                          Prob > F          =     0.0000\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "ln_sticky_~t | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "   ln_Assets |   .1352194   .0197462     6.85   0.000     .0965076    .1739312\n",
      "Leverage_R~o |   -.014872   .0043072    -3.45   0.001    -.0233161   -.0064279\n",
      "         ROA |  -.0999839   .0563461    -1.77   0.076    -.2104485    .0104807\n",
      "   ln_Length |   .7273371   .0070395   103.32   0.000     .7135364    .7411378\n",
      "       _cons |   .2434035   .2103267     1.16   0.247    -.1689352    .6557423\n",
      "-------------+----------------------------------------------------------------\n",
      "     sigma_u |  .30085918\n",
      "     sigma_e |  .15048498\n",
      "         rho |  .79988217   (fraction of variance due to u_i)\n",
      "------------------------------------------------------------------------------\n",
      "F test that all u_i=0: F(2676, 4710) = 1.40                  Prob > F = 0.0000\n",
      "(est1 stored)\n",
      "\n",
      ". eststo:xtreg ln_sticky_count  da_mj ln_Assets Leverage_Ratio ROA  ln_Length, \n",
      "> fe\n",
      "\n",
      "Fixed-effects (within) regression               Number of obs     =      7,391\n",
      "Group variable: stkno                           Number of groups  =      2,677\n",
      "\n",
      "R-squared:                                      Obs per group:\n",
      "     Within  = 0.7057                                         min =          1\n",
      "     Between = 0.7405                                         avg =        2.8\n",
      "     Overall = 0.7408                                         max =          3\n",
      "\n",
      "                                                F(5,4709)         =    2258.22\n",
      "corr(u_i, Xb) = 0.0544                          Prob > F          =     0.0000\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "ln_sticky_~t | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "       da_mj |  -.0200797   .0479264    -0.42   0.675    -.1140379    .0738785\n",
      "   ln_Assets |   .1349689    .019757     6.83   0.000     .0962359    .1737018\n",
      "Leverage_R~o |  -.0148281   .0043088    -3.44   0.001    -.0232754   -.0063807\n",
      "         ROA |  -.0980263   .0565444    -1.73   0.083    -.2088797    .0128271\n",
      "   ln_Length |   .7273588   .0070403   103.31   0.000     .7135565    .7411611\n",
      "       _cons |   .2458568   .2104266     1.17   0.243    -.1666778    .6583914\n",
      "-------------+----------------------------------------------------------------\n",
      "     sigma_u |  .30054263\n",
      "     sigma_e |  .15049815\n",
      "         rho |  .79951689   (fraction of variance due to u_i)\n",
      "------------------------------------------------------------------------------\n",
      "F test that all u_i=0: F(2676, 4709) = 1.40                  Prob > F = 0.0000\n",
      "(est2 stored)\n",
      "\n",
      ". eststo:xtreg sticky_ratio da_mj ln_Assets Leverage_Ratio ROA  ln_Length, fe\n",
      "\n",
      "Fixed-effects (within) regression               Number of obs     =      7,391\n",
      "Group variable: stkno                           Number of groups  =      2,677\n",
      "\n",
      "R-squared:                                      Obs per group:\n",
      "     Within  = 0.2526                                         min =          1\n",
      "     Between = 0.1066                                         avg =        2.8\n",
      "     Overall = 0.0031                                         max =          3\n",
      "\n",
      "                                                F(5,4709)         =     318.34\n",
      "corr(u_i, Xb) = -0.9305                         Prob > F          =     0.0000\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "sticky_ratio | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "       da_mj |  -.0119327   .0358769    -0.33   0.739    -.0822683    .0584029\n",
      "   ln_Assets |    .103893   .0147898     7.02   0.000     .0748981    .1328878\n",
      "Leverage_R~o |  -.0115422   .0032255    -3.58   0.000    -.0178658   -.0052187\n",
      "         ROA |  -.0630548   .0423282    -1.49   0.136    -.1460379    .0199282\n",
      "   ln_Length |  -.2073997   .0052702   -39.35   0.000    -.2177318   -.1970675\n",
      "       _cons |   1.166224    .157522     7.40   0.000     .8574073    1.475041\n",
      "-------------+----------------------------------------------------------------\n",
      "     sigma_u |    .230832\n",
      "     sigma_e |  .11266049\n",
      "         rho |  .80762058   (fraction of variance due to u_i)\n",
      "------------------------------------------------------------------------------\n",
      "F test that all u_i=0: F(2676, 4709) = 1.38                  Prob > F = 0.0000\n",
      "(est3 stored)\n",
      "\n",
      ". eststo:xtreg sticky_ratio ln_Assets Leverage_Ratio ROA  ln_Length, fe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed-effects (within) regression               Number of obs     =      7,391\n",
      "Group variable: stkno                           Number of groups  =      2,677\n",
      "\n",
      "R-squared:                                      Obs per group:\n",
      "     Within  = 0.2526                                         min =          1\n",
      "     Between = 0.1066                                         avg =        2.8\n",
      "     Overall = 0.0031                                         max =          3\n",
      "\n",
      "                                                F(4,4710)         =     397.97\n",
      "corr(u_i, Xb) = -0.9307                         Prob > F          =     0.0000\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "sticky_ratio | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "   ln_Assets |   .1040418   .0147816     7.04   0.000      .075063    .1330207\n",
      "Leverage_R~o |  -.0115683   .0032243    -3.59   0.000    -.0178894   -.0052473\n",
      "         ROA |  -.0642181   .0421795    -1.52   0.128    -.1469096    .0184734\n",
      "   ln_Length |  -.2074126   .0052696   -39.36   0.000    -.2177435   -.1970817\n",
      "       _cons |   1.164766   .1574461     7.40   0.000     .8560982    1.473434\n",
      "-------------+----------------------------------------------------------------\n",
      "     sigma_u |  .23101908\n",
      "     sigma_e |  .11264985\n",
      "         rho |   .8079015   (fraction of variance due to u_i)\n",
      "------------------------------------------------------------------------------\n",
      "F test that all u_i=0: F(2676, 4710) = 1.38                  Prob > F = 0.0000\n",
      "(est4 stored)\n",
      "\n",
      ". *esttab using Stickiness.rtf,r2 ar2 se replace star(* 0.1 ** 0.05 *** 0.01) n\n",
      "> ogap\n",
      ". eststo clear\n",
      "\n",
      ". \n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "clear\n",
    "use \"D:\\Study\\Data\\data_2022_new\\financial_data\\FSdata20220920.dta\"\n",
    "\n",
    "*Drop useless items\n",
    "drop if stkno == 9999    //Not existing stock code\n",
    "drop if macc != 12       //Accounting Period not equal to 12\n",
    "*Keep Consolidated Items (scflg==2) in duplicates group \n",
    "sort stkno acc\n",
    "by stkno acc: gen isdup = cond(_N == 1 | (_N != 1 & a01_scflg == 2), 0,1)\n",
    "drop if isdup == 1       //However, it will remain some duplicates\n",
    "drop isdup\n",
    "\n",
    "*To set time\n",
    "tostring acc, generate(date)\n",
    "gen year = yearly(substr(date,1,4), \"Y\")   // to extract year from YYYYMM format data\n",
    "format year %ty\n",
    "duplicates report stkno year\n",
    "duplicates tag stkno year , gen(isdup)\n",
    "drop if isdup == 1\n",
    "tab isdup\n",
    "xtset stkno year\n",
    "drop date\n",
    "\n",
    "*Sort Variables \n",
    "clonevar Assets = b01110\n",
    "clonevar Liabilities = c01082\n",
    "clonevar Net_Assets = c01083\n",
    "clonevar cfo = f01065\n",
    "clonevar sales = d01021\n",
    "clonevar Net_Income = d01114\n",
    "drop if missing(Assets,Liabilities,Net_Assets,cfo,sales, Net_Income,da_mj) \n",
    "\n",
    "gen ln_Assets = log(Assets)    \n",
    "gen Leverage_Ratio = Liabilities/Net_Assets\t\n",
    "gen ROA = Net_Income/Assets    \n",
    "keep stkno ename ntcls nkil year Assets Liabilities Net_Assets  cfo  sales Net_Income  ln_Assets  Leverage_Ratio ROA da_mj\n",
    "\n",
    "*Merge Dataset\n",
    "merge 1:1 stkno year using \"D:\\Study\\Data\\gdrive_XBRL\\text_data_formerge.dta\"\n",
    "drop if _merge == 1 | _merge == 2\n",
    "\n",
    "*Generate Variables for Regression\n",
    "gen ln_Length = log(unique)\n",
    "gen ln_sticky_count = log(sticky_count)\n",
    "drop if missing(ln_Length,ln_sticky_count,sticky_ratio)\n",
    "winsor2 ln_sticky_count sticky_ratio ln_Assets Leverage_Ratio ROA da_mj,replace cut(1 99)\n",
    "winsor2 Net_Assets cfo sales,replace cut(5 95) // Cut others for outreg tables\n",
    "\n",
    "*Generate Industry Identifier\n",
    "tostring nkil, generate(nkil_str)\n",
    "gen middle_nkil = substr(nkil_str,1,2)\n",
    "egen industry_code = group(middle_nkil)\n",
    "codebook middle_nkil                // check the industry code of each group\n",
    "egen mean_sticky_ratio  =mean(sticky_ratio), by(year middle_nkil)\n",
    "\n",
    "*Export decriptive data to word files\n",
    "*outreg2 using descriptive.doc,replace sum(log) keep(unique sticky_count sticky_ratio ln_Assets Leverage_Ratio ROA Net_Assets cfo sales) \n",
    "\n",
    "*Creating Graph Using Industry Identifier \n",
    "*Problem: the codebook does not include mid-code like \"11\", \"24\",\"25, etc\n",
    "*twoway (tsline mean_sticky_ratio if middle_nkil == \"11\") (tsline mean_sticky_ratio if middle_nkil == \"13\") ///  \n",
    "*(tsline mean_sticky_ratio if middle_nkil == \"25\")  (tsline mean_sticky_ratio if middle_nkil == \"27\"), /// \n",
    "*legend(order(1 \"石油\" 2 \"ゴム\" 3 \"造船\" 4 \"自動車\")) /// \n",
    "*title(\"Stickiness Score by Industry\") subtitle(\"from 2018 to 2022\") /// \n",
    "*ytitle(\"Score\")  /// \n",
    "*note(\"Source: Annual Reports from EDINET API\") /// \n",
    "*scheme(s2mono) saving(D:/Study/研究/Sticksore_by_industry.gph, replace) /// \n",
    "*graph export \"D:\\Study\\研究\\Sticksore_by_industry.jpg\", as(emf) name(\"Graph\") replace\n",
    "\n",
    "*Export using esttout \n",
    "eststo clear\n",
    "eststo:xtreg ln_sticky_count ln_Assets Leverage_Ratio ROA  ln_Length, fe\n",
    "eststo:xtreg ln_sticky_count  da_mj ln_Assets Leverage_Ratio ROA  ln_Length, fe\n",
    "eststo:xtreg sticky_ratio da_mj ln_Assets Leverage_Ratio ROA  ln_Length, fe\n",
    "eststo:xtreg sticky_ratio ln_Assets Leverage_Ratio ROA  ln_Length, fe\n",
    "*esttab using Stickiness.rtf,r2 ar2 se replace star(* 0.1 ** 0.05 *** 0.01) nogap\n",
    "eststo clear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
